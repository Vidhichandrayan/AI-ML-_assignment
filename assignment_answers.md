ACCUKNOX AI/ML Assignment:
Problem statement- assignment 1
1.	https://github.com/Vidhichandrayan/AI-ML-_assignment
2.	Send a link to the most complex Python code you have written
https://github.com/Vidhichandrayan/StudyPal_AiTutor/blob/main/src/vectorize_book.py
3.	Send a link to the most complex database code you have written
https://github.com/Vidhichandrayan/Recipe_Maker/blob/main/backend/database.py


Problem statement- assignment 2
1.	Where would you rate yourself on (LLM, Deep Learning, AI, ML). A, B, C [A = can code independently; B = can code under supervision; C = have little or no understanding] 
--As a keen learner, I enjoy exploring new technologies and continuously improving my skills. I have worked on LLM based projects such as AI Study Tutor and Smart Recipe Maker, where I implemented large language models as part of personal projects. I have also built deep learning projects and have a solid understanding of AI, Machine Learning, and Deep Learning concepts. I would rate myself at a B level, as I can code and build systems independently, but I am keen to gain real industry-level experience and learn best practices through guidance and hands-on work.

2.	What are the key architectural components to create a chatbot based on LLM? Please explain the approach on a high-level 

--The key components of an LLM-based chatbot include data preparation, a language model, and a retrieval system. In my projects like AI Study Tutor and Smart Recipe Maker, I first clean and organize the data so the model can learn meaningful patterns from it. One major challenge I noticed while building these systems was hallucination, where the model sometimes gives confident but incorrect answers.To overcome this, I used a retrieval layer in the architecture. When a user asks a question, the system performs a semantic search over stored content instead of simple keyword matching. It retrieves the most relevant text chunks and sends them along with the user’s query to the language model. This helped me get more reliable and grounded responses, because the model is always referring to real data rather than guessing.

3.	Please explain vector databases. If you were to select a vector database for a hypothetical problem (you may define the problem) which one will you choose, and why?

-- A vector database stores vector embeddings, which are numerical representations of text or other data generated by machine learning models. Large documents are first broken into smaller chunks, and each chunk is converted into an embedding. These embeddings are stored in the vector database so the system can perform semantic similarity search, meaning it can find information based on meaning rather than just keywords.In my AI study assistant (AI_StudyPal), which answers questions from textbooks and notes, I used ChromaDB. I chose ChromaDB because it is easy to use with Python and works well for storing and searching embeddings of text chunks. It helps retrieve the most relevant content for a user’s question, which is then passed to the LLM to generate more accurate and factual answers, reducing hallucinations.







